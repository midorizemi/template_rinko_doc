Automatically generated by Mendeley Desktop 1.17.6
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Steimle2013,
author = {Steimle, J{\"{u}}rgen and Jordt, Andreas and Maes, Pattie},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
file = {:home/tiwasaki/Documents/Mendeley/Steimle, Jordt, Maes/Proceedings of the SIGCHI Conference on Human Factors in Computing Systems/Steimle, Jordt, Maes - 2013 - Flexpad Highly Flexible Bending Interactions for Projected Handheld Displays.pdf:pdf},
isbn = {9781450318990},
keywords = {Flexible display,bending,deformation,depth camera,handheld display,projection,tracking,volumetric data},
pages = {237--246},
title = {{Flexpad : Highly Flexible Bending Interactions for Projected Handheld Displays}},
year = {2013}
}
@article{Metaxas1991a,
abstract = {A physically based approach to the recovery of nonrigid 3-D motion$\backslash$nand the tracking of nonrigid objects is presented. The approach makes$\backslash$nuse of deformable superquadrics, dynamics models that offer global$\backslash$ndeformation parameters which capture large-scale features and local$\backslash$ndeformation parameters which capture the details of complex shapes. The$\backslash$nequations of motion governing the behavior of the models make them$\backslash$nresponsive to externally applied forces. The authors extend their prior$\backslash$nformulation of these equations to include globally parameterized$\backslash$ntapering and bending deformations. They further generalize the$\backslash$nformulation to handle physically based point-to-point constraints$\backslash$nbetween models. Such constraints enable one to automatically assemble$\backslash$nobject models from interconnected deformable superquadric parts. These$\backslash$ncomposite models may be used to track the motions of articulated,$\backslash$nflexible objects},
author = {Metaxas, D. and Terzopoulos, D.},
doi = {10.1109/CVPR.1991.139712},
file = {:home/tiwasaki/Documents/Mendeley/Metaxas, Terzopoulos/Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition/Metaxas, Terzopoulos - 1991 - Constrained deformable superquadrics and nonrigid motion tracking.pdf:pdf},
isbn = {0-8186-2148-6},
issn = {1063-6919},
journal = {Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {337--343},
title = {{Constrained deformable superquadrics and nonrigid motion tracking}},
year = {1991}
}
@article{7516689,
abstract = {Dynamic projection mapping for moving objects has attracted much attention in recent years. However, conventional approaches have faced some issues, such as the target objects being limited to rigid objects, and the limited moving speed of the targets. In this paper, we focus on dynamic projection mapping onto rapidly deforming non-rigid surfaces with a speed sufficiently high that a human does not perceive any misalignment between the target object and the projected images. In order to achieve such projection mapping, we need a high-speed technique for tracking non-rigid surfaces, which is still a challenging problem in the field of computer vision. We propose the Deformable Dot Cluster Marker (DDCM), a novel fiducial marker for high-speed tracking of non-rigid surfaces using a high-frame-rate camera. The DDCM has three performance advantages. First, it can be detected even when it is strongly deformed. Second, it realizes robust tracking even in the presence of external and self occlusions. Third, it allows millisecond-order computational speed. Using DDCM and a high-speed projector, we realized dynamic projection mapping onto a deformed sheet of paper and a T-shirt with a speed sufficiently high that the projected images appeared to be printed on the objects.},
author = {Narita, G and Watanabe, Y and Ishikawa, M},
doi = {10.1109/TVCG.2016.2592910},
file = {:home/tiwasaki/Documents/Mendeley/Narita, Watanabe, Ishikawa/IEEE Transactions on Visualization and Computer Graphics (TVCG)/Narita, Watanabe, Ishikawa - 2016 - Dynamic Projection Mapping onto Deforming Non-rigid Surface using Deformable Dot Cluster Marker.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics (TVCG)},
keywords = {Cameras,Mirrors,Non-rigid surface tracking,Robustness,Shape,Target tracking,Visualization,fiducial marker,high-speed vision,projection mapping,spatial augmented reality},
number = {99},
pages = {1},
title = {{Dynamic Projection Mapping onto Deforming Non-rigid Surface using Deformable Dot Cluster Marker}},
year = {2016}
}
@article{1982763,
author = {正夫, 伊理 and 慎三, 児玉 and 信英, 須田},
doi = {10.11499/sicejl1962.21.763},
file = {:home/tiwasaki/Documents/Mendeley/正夫, 慎三, 信英/計測と制御/正夫, 慎三, 信英 - 1982 - 特異値分解とそのシステム制御への応用.pdf:pdf},
journal = {計測と制御},
number = {8},
pages = {763--772},
title = {特異値分解とそのシステム制御への応用},
volume = {21},
year = {1982}
}
@article{Lepetit2009,
abstract = {We propose a non-iterative solution to the PnP problem-the estimation of the pose of a calibrated camera from n 3D-to-2D point correspondences-whose computational complexity grows linearly with n. This is in contrast to state-of-the-art methods that are O(n5) or even O(n8), without being more accurate. Our method is applicable for all nges4 and handles properly both planar and non-planar configurations. Our central idea is to express the n 3D points as a weighted sum of four virtual control points. The problem then reduces to estimating the coordinates of these control points in the camera referential, which can be done in O(n) time by expressing these coordinates as weighted sum of the eigenvectors of a 12 x12 matrix and solving a small constant number of quadratic equations to pick the right weights. The advantages of our method are demonstrated by thorough testing on both synthetic and real-data.},
author = {Lepetit, Vincent and Moreno-Noguer, Francesc and Fua, Pascal},
doi = {10.1007/s11263-008-0152-6},
file = {:home/tiwasaki/Documents/Mendeley/Lepetit, Moreno-Noguer, Fua/International Journal of Computer Vision/Lepetit, Moreno-Noguer, Fua - 2009 - EPnP An accurate O(n) solution to the PnP problem.pdf:pdf},
isbn = {978-1-4244-1631-8},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {Absolute orientation,Perspective-n-Point,Pose estimation},
number = {2},
pages = {155--166},
title = {{EPnP: An accurate O(n) solution to the PnP problem}},
volume = {81},
year = {2009}
}
@article{4409116,
abstract = {We propose a non-iterative solution to the PnP problem—the estimation of the pose of a calibrated camera from n 3D-to-2D point correspondences—whose computa- tional complexity grows linearly with n. This is in contrast to state-of-the-art methods that are O(n5) or even O(n8), without being more accurate. Our method is applicable for all n ≥ 4 and handles properly both planar and non-planar configurations. Our central idea is to express the n 3D points as a weighted sum of four virtual control points. The problem then reduces to estimating the coordinates of these control points in the camera referential, which can be done in O(n) time by expressing these coordinates as weighted sum of the eigenvectors of a 12 × 12 matrix and solving a small constant number of quadratic equations to pick the right weights. The advantages of our method are demon- strated by thorough testing on both synthetic and real-data.},
author = {Moreno-Noguer, Francesc and Lepetit, Vincent and Fua, Pascal},
doi = {10.1109/ICCV.2007.4409116},
file = {:home/tiwasaki/Documents/Mendeley/Moreno-Noguer, Lepetit, Fua/IEEE 11th International Conference on Computer Vision, ICCV/Moreno-Noguer, Lepetit, Fua - 2007 - Accurate Non-iterative O(n) Solution to the PnP Problem.pdf:pdf},
isbn = {978-1-4244-1630-1},
issn = {1550-5499},
journal = {IEEE 11th International Conference on Computer Vision, ICCV},
keywords = {3D-to-2D point correspondences,Application software,Cameras,Centralized control,Computational complexity,Computer vision,Equations,Iterative methods,Laboratories,PnP problem,Robot vision systems,Transmission line matrix methods,camera calibration,computational complexity,computer vision,eigenvalues and eigenfunctions,eigenvectors,matrix algebra,noniterative solution,pose estimation},
pages = {1--8},
title = {{Accurate Non-iterative O(n) Solution to the PnP Problem*}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4409116},
year = {2007}
}
@article{2012a,
address = {aojima2012},
author = {青嶌, 恵倫香 and 颯佐, 達也 and 横塚, 慎太郎 and 横山, 正樹 and 紫合, 治},
file = {:home/tiwasaki/Documents/Mendeley/青嶌 et al/情報処理/青嶌 et al. - 2012 - 冷蔵庫の食材に基づくレシピ検索システム.pdf:pdf},
journal = {情報処理},
number = {1},
pages = {715--716},
title = {冷蔵庫の食材に基づくレシピ検索システム},
volume = {2012},
year = {2012}
}
@article{Lowe2004,
abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
author = {Lowe, David G.},
doi = {10.1023/B:VISI.0000029664.99615.94},
file = {:home/tiwasaki/Documents/Mendeley/Lowe/International Journal of Computer Vision/Lowe - 2004 - Distinctive image features from scale-invariant keypoints.pdf:pdf},
isbn = {1568811012},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {Image matching,Invariant features,Object recognition,Scale invariance},
number = {2},
pages = {91--110},
pmid = {20064111},
title = {{Distinctive image features from scale-invariant keypoints}},
volume = {60},
year = {2004}
}
@article{Morel2009a,
abstract = {If a physical object has a smooth or piecewise smooth boundary, its images obtained by cameras in varying positions undergo smooth apparent deformations. These deformations are locally well approximated by aﬃne transforms of the image plane. In consequence the solid object recognition problem has often been led back to the computation of aﬃne invariant image local features. Such invariant features could be obtained by normalization methods, but no fully aﬃne normalization method exists for the time being. Even scale invariance is only dealt with rigorously by the SIFT method. By simulating zooms out and normalizing translation and rotation, SIFT is invariant to four out of the six parameters of an aﬃne transform. The method proposed in this paper, Aﬃne-SIFT (ASIFT), simulates all image views obtainable by varying the two camera axis orientation parameters, namely the latitude and the longitude angles, left over by the SIFT method. Then it covers the other four parameters by using the SIFT method itself. The resulting method will be mathematically proved to be fully aﬃne invariant. Against any prognosis, simulating all views depending on the two camera orientation parameters is feasible with no dramatic computational load. A two-resolution scheme further reduces the ASIFT complexity to about twice that of SIFT. A new notion, the transition tilt, measuring the amount of distortion from one view to another is introduced. While an absolute tilt from a frontal to a slanted view exceeding 6 is rare, much higher transition tilts are common when two slanted views of an object are compared (see Fig. 1.1). The attainable transition tilt is measured for each aﬃne image comparison method. The new method permits to reliably identify features that have undergone transition tilts of large magnitude, up to 36 and higher. This fact is substantiated by many experiments which show that ASIFT outperforms signiﬁcantly the state-of-the-art methods SIFT, MSER, Harris-Aﬃne, and Hessian-Aﬃne.},
author = {Morel, Jean-Michel and Yu, Guoshen},
doi = {10.1137/080732730},
file = {:home/tiwasaki/Documents/Mendeley/Morel, Yu/SIAM Journal on Imaging Sciences/Morel, Yu - 2009 - ASIFT A New Framework for Fully Affine Invariant Image Comparison.pdf:pdf},
isbn = {1936-4954},
issn = {1936-4954},
journal = {SIAM Journal on Imaging Sciences},
keywords = {080732730,10,1137,68t10,68t40,68t45,93c85,affine invariance,affine normalization,ams subject classifications,descriptors,doi,feature transform,image matching,scale invariance,scale-invariant,sift},
number = {2},
pages = {438--469},
title = {{ASIFT: A New Framework for Fully Affine Invariant Image Comparison}},
volume = {2},
year = {2009}
}
@inproceedings{Looser2007,
abstract = {The Magic Lens concept is a focus and context technique which facilitates the visualization of complex and dense data. In this paper, we propose a new type of 3D tangible Magic Lens in the form of a flexible sheet. We describe new interaction techniques associated with this tool, and demonstrate how it can be applied in different AR applications.},
author = {Looser, Julian and Grasset, Rapha{\"{e}}l and Billinghurst, Mark},
booktitle = {Proceedings of the 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
doi = {10.1109/ISMAR.2007.4538825},
file = {:home/tiwasaki/Documents/Mendeley/Looser, Grasset, Billinghurst/Proceedings of the 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality/Looser, Grasset, Billinghurst - 2007 - A 3D Flexible and Tangible Magic Lens in Augmented Reality.pdf:pdf},
isbn = {9781424417506},
issn = {10772626},
keywords = {H.5.2 [information systems],Information interfaces and presentation - user int},
pages = {1----4},
title = {{A 3D Flexible and Tangible Magic Lens in Augmented Reality}},
year = {2007}
}
@article{Klein2009a,
abstract = {Camera phones are a promising platform for hand-held augmented reality. As their computational resources grow, they are becoming increasingly suitable for visual tracking tasks. At the same time, they still offer considerable challenges: Their cameras offer a narrow field-of-view not best suitable for robust tracking; images are often received at less than 15 Hz; long exposure times result in significant motion blur; and finally, a rolling shutter causes severe smearing effects. This paper describes an attempt to implement a keyframe-based SLAMsystem on a camera phone (specifically, the Apple iPhone 3 G). We describe a series of adaptations to the Parallel Tracking and Mapping system to mitigate the impact of the device's imaging deficiencies. Early results demonstrate a system capable of generating and augmenting small maps, albeit with reduced accuracy and robustness compared to SLAM on a PC.},
author = {Klein, Georg and Murray, David},
doi = {10.1109/ISMAR.2009.5336495},
file = {:home/tiwasaki/Documents/Mendeley/Klein, Murray/Science and Technology Proceedings - IEEE 2009 International Symposium on Mixed and Augmented Reality, ISMAR 2009/Klein, Murray - 2009 - Parallel tracking and mapping on a camera phone.pdf:pdf},
isbn = {9781424453900},
issn = {15534014},
journal = {Science and Technology Proceedings - IEEE 2009 International Symposium on Mixed and Augmented Reality, ISMAR 2009},
pages = {83--86},
pmid = {18717641},
title = {{Parallel tracking and mapping on a camera phone}},
year = {2009}
}
@article{Lowe2001,
abstract = {There have been important recent advances in object recognition through the matching of invariant local image features. However, the existing approaches are based on matching to individual training images. This paper presents a method for combining multiple images of a 3D object into a single model representation. This provides for recognition of 3D objects from any viewpoint, the generalization of models to non-rigid changes, and improved robustness through the combination of features acquired under a range of imaging conditions. The decision of whether to cluster a training image into an existing view representation or to treat it as a new view is based on the geometric accuracy of the match to previous model views. A new probabilistic model is developed to reduce the false positive matches that would otherwise arise due to loosened geometric constraints on matching 3D and non-rigid models. A system has been developed based on these approaches that is able to robustly recognize 3D objects in cluttered natural images in sub-second times.},
author = {Lowe, D.G.},
doi = {10.1109/CVPR.2001.990541},
file = {:home/tiwasaki/Documents/Mendeley/Lowe/Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001/Lowe - 2001 - Local feature view clustering for 3D object recognition.pdf:pdf},
isbn = {0-7695-1272-0},
issn = {1063-6919},
journal = {Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001},
keywords = {SIFT},
mendeley-tags = {SIFT},
pages = {682--688},
title = {{Local feature view clustering for 3D object recognition}},
volume = {1},
year = {2001}
}
@article{Little2002,
author = {Little, Jim},
file = {:home/tiwasaki/Documents/Mendeley/Little/Unknown/Little - 2002 - Localization and Mapping with.pdf:pdf},
keywords = {localization,mapping,visual landmarks},
number = {8},
pages = {735--758},
title = {{Localization and Mapping with}},
volume = {21},
year = {2002}
}
@article{Wagner2008,
abstract = {In this paper we present two techniques for natural feature tracking in real-time on mobile phones. We achieve interactive frame rates of up to 20 Hz for natural feature tracking from textured planar targets on current-generation phones. We use an approach based on heavily modified state-of-the-art feature descriptors, namely SIFT and Ferns. While SIFT is known to be a strong, but computationally expensive feature descriptor, Ferns classification is fast, but requires large amounts of memory. This renders both original designs unsuitable for mobile phones. We give detailed descriptions on how we modified both approaches to make them suitable for mobile phones. We present evaluations on robustness and performance on various devices and finally discuss their appropriateness for augmented reality applications.},
author = {Wagner, Daniel and Reitmayr, Gerhard and Mulloni, Alessandro and Drummond, Tom and Schmalstieg, Dieter},
doi = {10.1109/ISMAR.2008.4637338},
file = {:home/tiwasaki/Documents/Mendeley/Wagner et al/2008 7th IEEEACM International Symposium on Mixed and Augmented Reality/Wagner et al. - 2008 - Pose tracking from natural features on mobile phones.pdf:pdf},
isbn = {978-1-4244-2840-3},
journal = {2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality},
keywords = {Mobile phones,Natural features,Pose tracking},
pages = {125--134},
title = {{Pose tracking from natural features on mobile phones}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4637338},
year = {2008}
}
@article{Szeliski2010,
abstract = {As humans, we perceive the three-dimensional structure of the world around us with apparent ease. However, despite all of the recent advances in computer vision research, the dream of having a computer interpret an image at the same level as a two-year old remains elusive. Why is computer vision such a challenging problem, and what is the current state of the art?Computer Vision: Algorithms and Applications explores the variety of techniques commonly used to analyze and interpret images. It also describes challenging real-world applications where vision is being successfully used, both for specialized applications such as medical imaging and fun consumer-level tasks such as image editing and stitching, which students can apply to their own personal photos and videos.More than just a source of "recipes", this text/reference also takes a scientific approach to basic vision problems, formulating physical models of the imaging process before inverting this process to produce the best possible descriptions of a scene. Exercises are presented throughout the book, with a heavy emphasis on testing algorithms.Suitable for either an undergraduate or a graduate-level course in computer vision, this textbook focuses on basic techniques that work under real-world conditions and encourages students to push their creative boundaries.Dr. Richard Szeliski has over twenty years' experience in computer vision research, most notably at Digital Equipment Corporation and Microsoft.},
author = {Szeliski, Richard},
doi = {10.1007/978-1-84882-935-0},
file = {:home/tiwasaki/Documents/Mendeley/Szeliski/Computer/Szeliski - 2010 - Computer Vision Algorithms and Applications.pdf:pdf},
isbn = {1848829345},
issn = {10636919},
journal = {Computer},
pages = {832},
pmid = {16259003},
title = {{Computer Vision : Algorithms and Applications}},
url = {http://research.microsoft.com/en-us/um/people/szeliski/book/drafts/szelski{\_}20080330am{\_}draft.pdf},
volume = {5},
year = {2010}
}
@article{Ferrari2001,
abstract = {We present a system for planar augmented reality based on a new$\backslash$nreal-time affine region tracker. Instead of tracking fiducial points, we$\backslash$ntrack planar local image patches, and bring these into complete$\backslash$ncorrespondence, so a virtual texture can directly be added to them.$\backslash$nMoreover, the local image patches can be extracted in an invariant way,$\backslash$neven without any a priori information from previous frames. Hence, it is$\backslash$npossible to use them as natural beacons, that can be used to recognize$\backslash$nthe scene and to identify the individual patches. This results in a$\backslash$npowerful system that can work without artificial markers or fiducial$\backslash$npoints and with a minimal amount of user interference},
author = {Ferrari, V. and Tuytelaars, T. and Gool, L. Van},
doi = {10.1109/ISAR.2001.970518},
file = {:home/tiwasaki/Documents/Mendeley/Ferrari, Tuytelaars, Gool/Proceedings IEEE and ACM International Symposium on Augmented Reality/Ferrari, Tuytelaars, Gool - 2001 - Markerless augmented reality with a real-time affine region tracker.pdf:pdf},
isbn = {0-7695-1375-1},
issn = {0-7695-1375-1},
journal = {Proceedings IEEE and ACM International Symposium on Augmented Reality},
pages = {87--96},
pmid = {14681174},
title = {{Markerless augmented reality with a real-time affine region tracker}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=970518},
year = {2001}
}
@inproceedings{Ma:2010:ATA:1900179.1900193,
address = {New York, NY, USA},
author = {Ma, Xiaohu and Shi, Gang and Tian, Hongbo},
booktitle = {Proc. 9th ACM SIGGRAPH Conference on Virtual-Reality Continuum and Its Applications in Industry, VRCAI},
doi = {10.1145/1900179.1900193},
file = {:home/tiwasaki/Documents/Mendeley/Ma, Shi, Tian/Proc. 9th ACM SIGGRAPH Conference on Virtual-Reality Continuum and Its Applications in Industry, VRCAI/Ma, Shi, Tian - 2010 - Adaptive Threshold Algorithm for Multi-marker Augmented Reality System.pdf:pdf},
isbn = {978-1-4503-0459-7},
keywords = {ARToolKit,adaptive threshold,augmented reality,multi-marker recognition},
pages = {71--74},
publisher = {ACM},
series = {VRCAI '10},
title = {{Adaptive Threshold Algorithm for Multi-marker Augmented Reality System}},
url = {http://doi.acm.org/10.1145/1900179.1900193},
year = {2010}
}
@article{Shibata2010,
author = {史久, 柴田},
file = {:home/tiwasaki/Documents/Mendeley/史久/情報処理/史久 - 2010 - 拡張現実感（AR） 4．応用1：モバイルAR 位置情報に基づくARシステム.pdf:pdf},
journal = {情報処理},
number = {4},
pages = {385--391},
title = {{拡張現実感（AR）: 4．応用1：モバイルAR 位置情報に基づくARシステム}},
volume = {51},
year = {2010}
}
@incollection{Salzmann2008,
address = {Berlin, Heidelberg},
author = {Salzmann, Mathieu and Moreno-Noguer, Francesc and Lepetit, Vincent and Fua, Pascal},
booktitle = {Computer Vision – ECCV 2008},
chapter = {Closed-For},
doi = {10.1007/978-3-540-88693-8_43},
editor = {Forsyth, David and Torr, Philip and Zisserman, Andrew},
file = {:home/tiwasaki/Documents/Mendeley/Salzmann et al/Computer Vision – ECCV 2008/Salzmann et al. - 2008 - Closed-Form Solution to Non-rigid 3D Surface Registration.pdf:pdf},
isbn = {978-3-540-88693-8},
pages = {581--594},
publisher = {Springer Berlin Heidelberg},
title = {{Closed-Form Solution to Non-rigid 3D Surface Registration}},
url = {http://dx.doi.org/10.1007/978-3-540-88693-8{\_}43 http://link.springer.com/10.1007/978-3-540-88693-8{\_}43},
year = {2008}
}
@article{Uchiyama2011,
abstract = {This paper presents a novel approach for detecting and tracking markers with randomly scattered dots for augmented reality applications. Compared with traditionalmarkers with square pattern, our random dot markers have several significant advantages for flexible marker design, robustness against occlusion and user interaction. The retrieval and tracking of these markers are based on geometric feature based keypoint matching and tracking. We experimentally demonstrate that the discriminative ability of forty random dots per marker is applicable for retrieving up to one thousand markers.},
author = {Uchiyama, Hideaki and Marchand, Eric},
doi = {10.1109/ISMAR.2011.6092394},
file = {:home/tiwasaki/Documents/Mendeley/Uchiyama, Marchand/10th IEEE International Symposium on Mixed and Augmented Reality, ISMAR/Uchiyama, Marchand - 2011 - Deformable random Dot markers.pdf:pdf},
isbn = {9781457721830},
issn = {1087-8270},
journal = {10th IEEE International Symposium on Mixed and Augmented Reality, ISMAR},
keywords = {Artificial,Tracking,augmented,virtual realities},
pages = {237--238},
title = {{Deformable random Dot markers}},
year = {2011}
}
@article{2011,
abstract = {カメラに対して相対的に運動する平面を，画像上で精度良く安定して追跡することは，コンピュータビジョンの中心的課題である．これまで，照明変化，オクルージョンやモーションブラーなど，追跡の精度や安定性を損なう要因が色々と指摘され，それらへの対策が提案されてきている．本稿では，追跡対象の平面が視線に対して大きく傾いたり，あるいは遠く離れた場合に生じる画像上での実効的な解像度の低下もまた，追跡に悪影響を与えることを指摘する．そしてこの解像度の低下を，平面の姿勢に依存して決まる異方性ガウス関数の，追跡対象とするテンプレートへの畳み込みによってモデル化する．この解像度低下のモデルをMalisらの提案したESM法に組み込むと，従来方法よりもより高精度かつロバストな平面追跡が実行できることを，実験によって示す．It is one of the central issues in computer vision to track a planar object moving in space relatively to the camera in an accurate and stable fashion. Many studies have been conducted that point out several factors deteriorating tracking accuracy and stability and propose solutions to them. In this paper, we first point out that various forms of degradation in nominal image resolution, which typically occur in a situation where the planar object has a significantly oblique pose with respect to the viewing direction or in a situation where it moves to a distant location from the camera, can impair tracking performance. We then propose to model such degradation in image resolution by a convolution of the template with an anisotropic Gaussian function whose shape is determined by the current pose of the target plane. Incorporating this imaging model to ESM developed by Malis et al., we demonstrate through several experiments that it can perform more accurate and robust tracking of a planar object than the conventional method.},
author = {{伊藤 栄介} and {岡谷 貴之} and {出口 光一郎}},
file = {:home/tiwasaki/Documents/Mendeley/Ito, Okatani, Deguchi/10th IEEE International Symposium on Mixed and Augmented Reality, ISMAR/Ito, Okatani, Deguchi - 2011 - Accurate and robust planar tracking based on a model of image sampling and reconstruction process.pdf:pdf},
issn = {1884-0930},
journal = {コンピュータビジョンとイメージメディア（CVIM）},
number = {22},
pages = {1--8},
publisher = {情報処理学会},
title = {画像の標本化過程のモデルに基づく高精度・頑健な平面追跡},
url = {http://ci.nii.ac.jp/naid/110007891097},
volume = {2011},
year = {2011}
}
@article{Oikawa2012,
author = {Marina, Oikawa and Takafumi, Taketomi and Goshiro, Yamamoto and Makoto, Fujisawa and Toshiyuki, Amano and Jun, Miyazaki and Hirokazu, Kato},
file = {:home/tiwasaki/Documents/Mendeley/Marina et al/SBC Journal on 3D Interactive Systems/Marina et al. - 2012 - A model-based tracking framework for textureless 3D rigid curved objects.pdf:pdf},
journal = {SBC Journal on 3D Interactive Systems},
number = {2},
pages = {2--15},
title = {{A model-based tracking framework for textureless 3D rigid curved objects}},
url = {http://www.seer.ufrgs.br/jis/article/viewFile/36736/23851},
volume = {3},
year = {2012}
}
@article{2012,
author = {哲平, 中山 and 英裕, 大城 and 直道, 末田 and 啓二, 行天},
file = {:home/tiwasaki/Documents/Mendeley/哲平 et al/平成 24 年度 電気関係学会九州支部連合大会講演論文集/哲平 et al. - 2012 - 視覚的看板翻訳のためのASIFTを用いた看板領域抽出.pdf:pdf},
journal = {平成 24 年度 電気関係学会九州支部連合大会講演論文集},
pages = {436--437},
title = {{視覚的看板翻訳のためのASIFTを用いた看板領域抽出}},
volume = {2012},
year = {2012}
}
@inproceedings{Salzmann2008a,
author = {Salzmann, Mathieu and Urtasun, Raquel and Fua, Pascal},
booktitle = {2008 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2008.4587499},
file = {:home/tiwasaki/Documents/Mendeley/Salzmann, Urtasun, Fua/2008 IEEE Conference on Computer Vision and Pattern Recognition/Salzmann, Urtasun, Fua - 2008 - Local deformation models for monocular 3D shape recovery.pdf:pdf},
isbn = {978-1-4244-2242-5},
month = {jun},
pages = {1--8},
publisher = {IEEE},
title = {{Local deformation models for monocular 3D shape recovery}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4587499},
year = {2008}
}
@article{2010,
author = {直, 橋本},
file = {:home/tiwasaki/Documents/Mendeley/直/情報処理/直 - 2010 - 拡張現実感（AR） 3．基礎3：開発用ツール.pdf:pdf},
journal = {情報処理},
number = {4},
pages = {379--384},
title = {{拡張現実感（AR）: 3．基礎3：開発用ツール}},
volume = {51},
year = {2010}
}
@article{Rublee2011,
abstract = {Feature matching is at the base of many computer vision problems, such as object recognition or structure from motion. Current methods rely on costly descriptors for detection and matching. In this paper, we propose a very fast binary descriptor based on BRIEF, called ORB, which is rotation invariant and resistant to noise. We demonstrate through experiments how ORB is at two orders of magnitude faster than SIFT, while performing as well in many situations. The efficiency is tested on several real-world applications, including object detection and patch-tracking on a smart phone.},
author = {Rublee, Ethan and Rabaud, Vincent and Konolige, Kurt and Bradski, Gary},
doi = {10.1109/ICCV.2011.6126544},
file = {:home/tiwasaki/Documents/Mendeley/Rublee et al/Proceedings of the IEEE International Conference on Computer Vision/Rublee et al. - 2011 - ORB An efficient alternative to SIFT or SURF.pdf:pdf},
isbn = {9781457711015},
issn = {1550-5499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {2564--2571},
pmid = {20033598},
title = {{ORB: An efficient alternative to SIFT or SURF}},
year = {2011}
}
@inproceedings{Fujimoto2014,
abstract = {We demonstrate the geometrically-correct projection-based texture mapping onto a deformable object like a cloth. This system can be used to simulate design that involves change in shape, such as sheets of malleable material. The geometrically-correct projection-based texture mapping onto a cloth is conducted using the measurement of object's 3D shape and the detection of the retro-reflective marker on the object's surface. Rapid prototyping is used as an example application of this projection technique. {\textcopyright} 2014 IEEE.},
author = {Fujimoto, Yuichiro and Miyazaki, Jun and Taketomi, Takafumi and Kato, Hirokazu and Thomas, Bruce H. and Yamamoto, Goshiro and Smith, Ross T.},
booktitle = {IEEE Virtual Reality, VR},
doi = {10.1109/VR.2014.6802105},
file = {:home/tiwasaki/Documents/Mendeley/Fujimoto et al/IEEE Virtual Reality, VR/Fujimoto et al. - 2014 - Geometrically-correct projection-based texture mapping onto a cloth.pdf:pdf},
isbn = {9781479928712},
issn = {10772626},
keywords = {Projection-based augmented reality,deformable marker,product design support},
number = {4},
pages = {169--170},
pmid = {24650981},
title = {{Geometrically-correct projection-based texture mapping onto a cloth}},
volume = {20},
year = {2014}
}
@article{Hamilton1844,
author = {Hamilton, William Rowan},
doi = {10.1080/14786444408644923},
file = {:home/tiwasaki/Documents/Mendeley/Hamilton/Philosophical Magazine Series 3/Hamilton - 1844 - II. On quaternions or on a new system of imaginaries in algebra.pdf:pdf},
issn = {1941-5966},
journal = {Philosophical Magazine Series 3},
number = {163},
pages = {10--13},
title = {{II. On quaternions; or on a new system of imaginaries in algebra}},
url = {http://dx.doi.org/10.1080/14786444408644923},
volume = {25},
year = {1844}
}
@article{Ashdown2006,
abstract = {We wish to compensate for irregularities in the output of digital projectors that occur when they are used in non-ideal situations, such as those with varying surface reflectance and ambient light. We transform the image to be displayed into a compensation image that will produce the desired appearance. In contrast to previous methods, the transformation is based on both a radiometric model of the system and the content of the image. We present a five-stage framework for performing content-dependent photometric compensation, and the details of a specific implementation. The original image is converted to a perceptually-uniform space, the desired chrominance is fitted to the gamut of the projector, a luminance range is calculated within which the fitted chrominance values can be produced, the original luminance is fitted to that range, and finally the fitted values are converted to a compensation image. Our method balances strict compensation against dynamic range in the final output, so we can produce a good result even when removal of all visible spatial variation is not possible.},
author = {Ashdown, Mark and Okabe, Takahiro and Sato, Imari and Sato, Yoichi},
doi = {10.1109/CVPRW.2006.172},
file = {:home/tiwasaki/Documents/Mendeley/Ashdown et al/Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition/Ashdown et al. - 2006 - Robust content-dependent photometric projector compensation.pdf:pdf},
isbn = {0769526462},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {Robust Content-Dependent Photometric Projector Com},
pages = {4--6},
title = {{Robust content-dependent photometric projector compensation}},
year = {2006}
}
@inproceedings{Collins2015,
author = {Collins, Toby and Bartoli, Adrien},
booktitle = {Proc. the IEEE International Symposium on Mixed and Augmented Reality, ISMAR},
doi = {10.1109/ISMAR.2015.35},
file = {:home/tiwasaki/Documents/Mendeley/Collins, Bartoli/Proc. the IEEE International Symposium on Mixed and Augmented Reality, ISMAR/Collins, Bartoli - 2015 - POSTER Realtime shape-from-template System and applications.pdf:pdf},
isbn = {9781467376600},
pages = {116--119},
title = {{[POSTER] Realtime shape-from-template: System and applications}},
year = {2015}
}
@article{Ito2011,
abstract = {It is one of the central issues in augmented reality and computer vision to track a planar object moving relatively to a camera in an accurate and robust manner. In previous studies, it was pointed out that there are several factors making the tracking difficult, such as illumination change and motion blur, and effective solutions were proposed for them. In this paper, we point out that degradation in effective image resolution can also deteriorate tracking performance, which typically occurs when the plane being tracked has an oblique pose with respect to the viewing direction, or when it moves to a distant location from the camera. The deterioration tends to become significantly large for extreme configurations, e.g., when the planar object has nearly a right angle with the viewing direction. Such configurations can frequently occur in AR applications targeted at ordinary users. To cope with this problem, we model the sampling and reconstruction process of images, and present a tracking algorithm that incorporates the model to correctly handle these configurations. We show through several experiments that the proposed method shows better performance than conventional methods.},
author = {Ito, Eisuke and Okatani, Takayuki and Deguchi, Koichiro},
doi = {10.1109/ISMAR.2011.6092364},
file = {:home/tiwasaki/Documents/Mendeley/Ito, Okatani, Deguchi/10th IEEE International Symposium on Mixed and Augmented Reality, ISMAR/Ito, Okatani, Deguchi - 2011 - Accurate and robust planar tracking based on a model of image sampling and reconstruction process.pdf:pdf},
isbn = {9781457721830},
journal = {10th IEEE International Symposium on Mixed and Augmented Reality, ISMAR},
keywords = {Image formation process,Image sampling and reconstruction,Planar tracking,Visual tracking},
number = {2},
pages = {1--8},
title = {{Accurate and robust planar tracking based on a model of image sampling and reconstruction process}},
volume = {2011},
year = {2011}
}
@article{Salzmann2011,
author = {Salzmann, Mathieu and Fua, Pascal and Member, Senior},
file = {:home/tiwasaki/Documents/Mendeley/Salzmann, Fua, Member/The IEEE Transactions on Pattern Analysis and Machine Intelligence/Salzmann, Fua, Member - 2011 - Linear Local Models for Monocular Reconstruction of Deformable Surfaces.pdf:pdf},
journal = {The IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Deformable surfaces,Deformation models,Monocular shape recovery,non-planar},
mendeley-tags = {non-planar},
number = {5},
pages = {931--944},
title = {{Linear Local Models for Monocular Reconstruction of Deformable Surfaces}},
volume = {33},
year = {2011}
}
@article{Agarwal:2011:BRD:2001269.2001293,
abstract = {We wish to compensate for irregularities in the output of digital projectors that occur when they are used in non-ideal situations, such as those with varying surface reflectance and ambient light. We transform the image to be displayed into a compensation image that will produce the desired appearance. In contrast to previous methods, the transformation is based on both a radiometric model of the system and the content of the image. We present a five-stage framework for performing content-dependent photometric compensation, and the details of a specific implementation. The original image is converted to a perceptually-uniform space, the desired chrominance is fitted to the gamut of the projector, a luminance range is calculated within which the fitted chrominance values can be produced, the original luminance is fitted to that range, and finally the fitted values are converted to a compensation image. Our method balances strict compensation against dynamic range in the final output, so we can produce a good result even when removal of all visible spatial variation is not possible.},
address = {New York, NY, USA},
author = {Agarwal, Sameer and Furukawa, Yasutaka and Snavely, Noah and Simon, Ian and Curless, Brian and Seitz, Steven M and Szeliski, Richard},
doi = {10.1145/2001269.2001293},
file = {:home/tiwasaki/Documents/Mendeley/Agarwal et al/Commun. ACM/Agarwal et al. - 2011 - Building Rome in a Day.pdf:pdf},
issn = {0001-0782},
journal = {Commun. ACM},
number = {10},
pages = {105--112},
publisher = {ACM},
title = {{Building Rome in a Day}},
url = {http://doi.acm.org/10.1145/2001269.2001293},
volume = {54},
year = {2011}
}
@article{Taketomi2011a,
abstract = {In the field of augmented reality (AR), many kinds of vision-based extrinsic camera parameter estimation methods have been proposed to achieve geometric registration between real and virtual worlds. Previously, a feature landmark-based camera parameter estimation method was proposed. This is an effective method for implementing outdoor AR applications because a feature landmark database can be automatically constructed using the structure-from-motion (SfM) technique. However, the previous method cannot work in real time because it entails a high computational cost or matching landmarks in a database with image features in an input image. In addition, the accuracy of estimated camera parameters is insufficient for applications that need to overlay CG objects at a position close to the user's viewpoint. This is because it is difficult to compensate for visual pattern change of close landmarks when only the sparse depth information obtained by the SfM is available. In this paper, we achieve fast and accurate feature landmark-based camera parameter estimation by adopting the following approaches. First, the number of matching candidates is reduced to achieve fast camera parameter estimation by tentative camera parameter estimation and by assigning priorities to landmarks. Second, image templates of landmarks are adequately compensated for by considering the local 3-D structure of a landmark using the dense depth information obtained by a laser range sensor. To demonstrate the effectiveness of the proposed method, we developed some AR applications using the proposed method. ?? 2011 Elsevier Ltd. All rights reserved.},
author = {Taketomi, Takafumi and Sato, Tomokazu and Yokoya, Naokazu},
doi = {10.1016/j.cag.2011.04.007},
file = {:home/tiwasaki/Documents/Mendeley/Taketomi, Sato, Yokoya/Computers and Graphics (Pergamon)/Taketomi, Sato, Yokoya - 2011 - Real-time and accurate extrinsic camera parameter estimation using feature landmark database for augment.pdf:pdf},
issn = {00978493},
journal = {Computers and Graphics (Pergamon)},
keywords = {Augmented reality,Extrinsic camera parameter estimation,Landmark database,Natural features},
number = {4},
pages = {768--777},
title = {{Real-time and accurate extrinsic camera parameter estimation using feature landmark database for augmented reality}},
url = {http://dx.doi.org/10.1016/j.cag.2011.04.007},
volume = {35},
year = {2011}
}
@inproceedings{Salzmann2009,
abstract = {In recent years, 3D deformable surface reconstruction from single images has attracted renewed interest. It has been shown that preventing the surface from either shrinking or stretching is an effective way to resolve the ambiguities inherent to this problem. However, while the geodesic distances on the surface may not change, the Euclidean ones decrease when folds appear. Therefore, when applied to discrete surface representations, such constant-distance constraints are only effective for smoothly deforming surfaces, and become inaccurate for more flexible ones that can exhibit sharp folds. In such cases, surface points must be allowed to come closer to each other. In this paper, we show that replacing the equality constraints of earlier approaches by inequality constraints that let the mesh representation of the surface shrink but not expand yields not only a more faithful representation, but also a convex formulation of the reconstruction problem. As a result, we can accurately reconstruct surfaces undergoing complex deformations that include sharp folds from individual images. ER -},
author = {Salzmann, Mathieu and Fua, Pascal},
booktitle = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, CVPR Workshops 2009},
doi = {10.1109/CVPRW.2009.5206759},
file = {:home/tiwasaki/Documents/Mendeley/Salzmann, Fua/IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, CVPR Workshops 2009/Salzmann, Fua - 2009 - Reconstructing sharply folding surfaces A convex formulation.pdf:pdf},
isbn = {9781424439935},
issn = {1063-6919},
pages = {1054--1061},
title = {{Reconstructing sharply folding surfaces: A convex formulation}},
year = {2009}
}
@article{110009598081,
author = {直樹, 金山 and 裕樹, 高橋},
file = {:home/tiwasaki/Documents/Mendeley/直樹, 裕樹/映情学技報報告/直樹, 裕樹 - 2013 - 円柱上のARマーカの曲面形状推定.pdf:pdf},
issn = {13426893},
journal = {映情学技報報告},
number = {17},
pages = {149--150},
publisher = {一般社団法人映像情報メディア学会},
title = {{円柱上のARマーカの曲面形状推定}},
url = {http://ci.nii.ac.jp/naid/110009598081/},
volume = {37},
year = {2013}
}
@article{Cootes2001,
abstract = {We describe a new method of matching statistical models of appearance to images. A set of model parameters control modes of shape and gray-level variation learned from a training set. We construct an efficient iterative matching algorithm by learning the relationship between perturbations in the model parameters and the induced image errors},
archivePrefix = {arXiv},
arxivId = {10.1.1.128.4967},
author = {{Timothy, F.}, Cootes and {Gareth, J.}, Edwards and {Christopher, J.}, Taylor},
doi = {10.1109/34.927467},
eprint = {10.1.1.128.4967},
file = {:home/tiwasaki/Documents/Mendeley/Timothy, F., Gareth, J., Christopher, J/IEEE Trans. Pattern Analysis and Machine Intelligence/Timothy, F., Gareth, J., Christopher, J. - 2001 - Active Appearance Models.pdf:pdf},
isbn = {0162-8828},
issn = {01628828},
journal = {IEEE Trans. Pattern Analysis and Machine Intelligence},
number = {6},
pages = {681--685},
pmid = {927467},
title = {{Active Appearance Models}},
volume = {23},
year = {2001}
}
@article{Pang2012,
abstract = {Fast and robust feature extraction is crucial for many computer vision applications such as image matching. The representative and the state-of-the-art image features include Scale Invariant Feature Transform (SIFT), Speeded Up Robust Features (SURF), and Affine SIFT (ASIFT). However, neither of them is fully affine invariant and computation efficient at the same time. To overcome this problem, we propose in this paper a fully affine invariant SURF algorithm. The proposed algorithm makes full use of the affine invariant advantage of ASIFT and the efficient merit of SURF while avoids their drawbacks. Experimental results on applications of image matching demonstrate the robustness and efficiency of the proposed algorithm. {\textcopyright} 2012 Elsevier B.V.},
author = {Pang, Yanwei and Li, Wei and Yuan, Yuan and Pan, Jing},
doi = {10.1016/j.neucom.2011.12.006},
file = {:home/tiwasaki/Documents/Mendeley/Pang et al/Neurocomputing/Pang et al. - 2012 - Fully affine invariant SURF for image matching.pdf:pdf},
isbn = {09252312},
issn = {09252312},
journal = {Neurocomputing},
keywords = {FAIR-SURF,Feature extraction,Image matching,SURF},
pages = {6--10},
publisher = {Elsevier},
title = {{Fully affine invariant SURF for image matching}},
url = {http://dx.doi.org/10.1016/j.neucom.2011.12.006},
volume = {85},
year = {2012}
}
@article{Salzmann2005,
author = {Salzmann, Mathieu and Ilic, S. and Fua, P.},
doi = {10.5244/C.19.12},
file = {:home/tiwasaki/Documents/Mendeley/Salzmann, Ilic, Fua/Procedings of the British Machine Vision Conference 2005/Salzmann, Ilic, Fua - 2005 - Physically Valid Shape Parameterization for Monocular 3-D Deformable Surface Tracking.pdf:pdf},
isbn = {1-901725-29-4},
journal = {Procedings of the British Machine Vision Conference 2005},
pages = {12.1--12.10},
title = {{Physically Valid Shape Parameterization for Monocular 3-D Deformable Surface Tracking}},
url = {http://www.bmva.org/bmvc/2005/papers/paper-13.html},
year = {2005}
}
@article{Torresani2004a,
abstract = {This paper presents an algorithm for learning the time-varying shape$\backslash$nof a non-rigid 3D object from uncalibrated 2D tracking data. We model$\backslash$nshape motion as a rigid component (rotation and translation) combined$\backslash$nwith a non-rigid deformation. Reconstruction is ill-posed if arbitrary$\backslash$ndeformations are allowed. We constrain the problem by assuming that$\backslash$nthe object shape at each time instant is drawn from a Gaussian distribution.$\backslash$nBased on this assumption, the algorithm simultaneously estimates$\backslash$n3D shape and motion for each time frame, learns the parameters of$\backslash$nthe Gaussian, and robustly fills-in missing data points. We then$\backslash$nextend the algorithm to model temporal smoothness in object shape,$\backslash$nthus allowing it to handle severe cases of missing data.},
author = {Torresani, Lorenzo and Hertzmann, Aaron and Bregler, Christoph},
file = {:home/tiwasaki/Documents/Mendeley/Torresani, Hertzmann, Bregler/Advances in Neural Information Processing Systems/Torresani, Hertzmann, Bregler - 2004 - Learning Non-Rigid 3D Shape from 2D Motion.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
pages = {1555--1562},
title = {{Learning Non-Rigid 3D Shape from 2D Motion}},
url = {http://papers.nips.cc/paper/2509-learning-non-rigid-3d-shape-from-2d-motion.pdf},
volume = {16},
year = {2004}
}
@article{Fujiki2001,
abstract = {複数の2次元画像からカメラ運動と対象物体の立体形状を同時に復元する問題はコ ンピュータビジョンにおいて基本的かつ重要な問題であり，その中でも点特徴の対応に基づいた複数の2次元画像からのカメラ運動と対称物体の3次元復元問題はもっとも基本的かつ重要な問題である．この問題を解決する手法の中でも因子分解法は実際のカメラモデルである透視射影をアフィン射影で近似することにより問題を簡略化することによって数値計算上安定でかつ比較的良い結果を与える優れた手法である．因子分解法は手法として優れているだけでなく，複数のアフィン近似射影画像からのカメラ運動と対象物体の立体形状を同時に復元する問題を理解する上で非 常に有用な方法である．本稿では，因子分解法を通して点対応を用いた複数のアフィン近似射影画像からのカメラ運動と立体形状の復元の数理について解説する．また，透視射影による像からアフィン近似射影による像を推定することによって，透視射影画像からのカメラ運動と立体形状を同時に復元する手法及び逐次型因子分解法についても紹介する．},
author = {藤木, 淳},
file = {:home/tiwasaki/Documents/Mendeley/藤木/統計数理/藤木 - 2001 - 点対応を用いた複数の2次元画像からの3次元形状復元 -因子分解法の数理-.pdf:pdf},
issn = {09118179},
journal = {統計数理},
keywords = {tructure from motion,因子分解法,計量アフィン射影,透視射影,逐次型},
number = {1},
pages = {77--107},
title = {点対応を用いた複数の2次元画像からの3次元形状復元 -因子分解法の数理-},
volume = {49},
year = {2001}
}
@article{Yu2011,
abstract = {ASIFT is a fully affine invariant image comparison method. It permits to identify features with transition tilts up to 36 and higher.},
author = {Yu, Guoshen and Morel, Jean-Michel},
doi = {10.5201/ipol.2011.my-asift},
issn = {21051232},
journal = {Image Processing On Line, IPOL},
keywords = {affine invariant matching,sift},
pages = {1--28},
title = {{ASIFT: An Algorithm for Fully Affine Invariant Comparison}},
volume = {1},
year = {2011}
}
@article{Suk2000,
abstract = { First, for five-point sets, which are simultaneously to the transform and to permutation of the points, are derived. },
author = {Suk, Tom{\'{a}}{\v{s}} and Flusser, Jan},
doi = {10.1016/S0031-3203(99)00049-7},
file = {:home/tiwasaki/Documents/Mendeley/Suk, Flusser/Pattern Recognition/Suk, Flusser - 2000 - Point-based projective invariants.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {control points,permutation invariants,point set matching,point-based invariants,projective invariants,projective transform,registra-,tion},
number = {2},
pages = {251--261},
pmid = {9052161673991735586},
title = {{Point-based projective invariants}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320399000497},
volume = {33},
year = {2000}
}
@article{Kanbara2010,
author = {誠之, 神原},
file = {:home/tiwasaki/Documents/Mendeley/神原 誠之/情報処理/神原 誠之 - 2010 - 拡張現実感（AR） 1．基礎1：拡張現実感（Augmented Reality：AR）概論.pdf:pdf},
journal = {情報処理},
number = {4},
pages = {367--372},
title = {{拡張現実感（AR）: 1．基礎1：拡張現実感（Augmented Reality：AR）概論}},
volume = {51},
year = {2010}
}
@article{Rekimoto1996,
abstract = {The paper introduces a novel technique for producing augmented reality systems that simultaneously identify real world objects and estimate their coordinate systems. This method utilizes a 2D matrix marker, a square shaped barcode, which can identify a large number of objects. It also acts as a landmark to register information on real world images. As a result, it costs virtually nothing to produce and attach codes to various kinds of real world objects, because the matrix code is printable. We have developed an augmented reality system based on this method, and demonstrated several potential applications},
author = {Rekimoto, J.},
doi = {10.1109/APCHI.1998.704151},
file = {:home/tiwasaki/Documents/Mendeley/Rekimoto/Proceedings. 3rd Asia Pacific Computer Human Interaction (Cat. No.98EX110)/Rekimoto - 1996 - Matrix a realtime object identification and registration method for augmented reality.pdf:pdf},
isbn = {0-8186-8347-3},
journal = {Proceedings. 3rd Asia Pacific Computer Human Interaction (Cat. No.98EX110)},
keywords = {AR},
mendeley-tags = {AR},
pages = {63--68},
title = {{Matrix: a realtime object identification and registration method for augmented reality}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=704151},
year = {1996}
}
@article{Ostlund2012,
author = {Ostlund, Jonas and Varol, Aydin and Ngo, Dat Tien and Fua, Pascal},
doi = {10.1007/978-3-642-33712-3_30},
file = {:home/tiwasaki/Documents/Mendeley/Ostlund et al/Computer Vision – ECCV 2012/Ostlund et al. - 2012 - Laplacian Meshes for Monocular 3D Shape Recovery.pdf:pdf},
journal = {Computer Vision – ECCV 2012},
pages = {412--425},
title = {{Laplacian Meshes for Monocular 3D Shape Recovery}},
volume = {3},
year = {2012}
}
@article{Lee2004,
author = {Lee, Gun A. and Nelles, Claudia and Billinghurst, Mark and Kim, Gerard Jounghyun},
file = {:home/tiwasaki/Documents/Mendeley/Lee et al/Proceedings of the Third IEEE and ACM International Symposium on Mixed and Augmented Reality 2004/Lee et al. - 2004 - Immersive Authoring of Tangible Augmented Reality Applications.pdf:pdf},
isbn = {0769521916},
journal = {Proceedings of the Third IEEE and ACM International Symposium on Mixed and Augmented Reality 2004},
number = {Ismar},
pages = {172----181},
title = {{Immersive Authoring of Tangible Augmented Reality Applications}},
volume = {10},
year = {2004}
}
@article{Arya:1998:OAA:293347.293348,
abstract = {Consider a set of S of n data points in real d-dimensional space, Rd, where distances are measured using any Minkowski metric. In nearest neighbor searching, we preprocess S into a data structure, so that given any query point q Rd, is the closest point of S to q can be reported quickly. Given any positive real {\&}egr;, data point p is a (1 +{\&}egr;)-approximate nearest neighbor of q if its distance from q is within a factor of (1 + {\&}egr;) of the distance to the true nearest neighbor. We show that it is possible to preprocess a set of n points in Rd in O(dn log n) time and O(dn) space, so that given a query point q Rd, and {\&}egr; {\textgreater} 0, a (1 + {\&}egr;)-approximate nearest neighbor of q can be computed in O(cd, {\&}egr; log n) time, where cd,{\&}egr;d 1 + 6d/e;d is a factor depending only on dimension and {\&}egr;. In general, we show that given an integer k 1, (1 + {\&}egr;)-approximations to the k nearest neighbors of q can be computed in additional O(kd log n) time.},
address = {New York, NY, USA},
author = {Arya, Sunil and Mount, David M. and Netanyahu, Nathan S. and Silverman, Ruth and Wu, Angela Y.},
doi = {10.1145/293347.293348},
file = {:home/tiwasaki/Documents/Mendeley/Arya et al/J. ACM/Arya et al. - 1998 - An Optimal Algorithm for Approximate Nearest Neighbor Searching Fixed Dimensions.pdf:pdf},
issn = {0004-5411},
journal = {J. ACM},
keywords = {approximation algorithms,box-decomposition trees,closet-point queries,nearest neighbor searching,post-office problem,priority search},
number = {6},
pages = {891--923},
publisher = {ACM},
title = {{An Optimal Algorithm for Approximate Nearest Neighbor Searching Fixed Dimensions}},
url = {http://doi.acm.org/10.1145/293347.293348},
volume = {45},
year = {1998}
}
@article{Fischler:1981:RSC:358669.358692,
address = {New York, NY, USA},
author = {Fischler, Martin A and Bolles, Robert C},
doi = {10.1145/358669.358692},
file = {:home/tiwasaki/Documents/Mendeley/Fischler, Bolles/Commun. ACM/Fischler, Bolles - 1981 - Random Sample Consensus A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartogr.pdf:pdf},
issn = {0001-0782},
journal = {Commun. ACM},
keywords = {automated cartography,camera calibration,image matching,location determination,model fitting,scene analysis},
number = {6},
pages = {381--395},
publisher = {ACM},
title = {{Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography}},
url = {http://doi.acm.org/10.1145/358669.358692},
volume = {24},
year = {1981}
}
@inproceedings{1544840,
abstract = {Reconstruction of 3D structures from uncalibrated image sequences has a wealthy history. Most work has been focused on rigid objects or static scenes. This paper studies the problem of perspective reconstruction of deformable structures such as dynamic scenes from an uncalibrated image sequence. The task requires decomposing the image measurements into a composition of three factors: 3D deformable structures, rigid rotations and translations, and intrinsic camera parameters. We develop a factorization algorithm that consists of two steps. In the first step we recover the protective depths iteratively using the sub-space constraints embedded in the image measurements of the deformable structures. In the second step, we scale the image measurements by the reconstructed projective depths. We then extend the linear closed-form solution for weak-perspective reconstruction by J. Xiao, et al. (2004) to factorize the scaled measurements and simultaneously reconstruct the deformable shapes and underlying shape model, the rigid motions, and the varying camera parameters such as focal lengths. The accuracy and robustness of the proposed method is demonstrated quantitatively on synthetic data and qualitatively on real image sequences},
author = {Xiao, Jing and Kanade, T},
booktitle = {Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},
doi = {10.1109/ICCV.2005.241},
file = {:home/tiwasaki/Documents/Mendeley/Xiao, Kanade/Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1/Xiao, Kanade - 2005 - Uncalibrated perspective reconstruction of deformable structures.pdf:pdf},
issn = {1550-5499},
keywords = {3D deformable structure,Cameras,History,Image reconstruction,Image sequences,Iterative algorithms,Layout,Protection,Rotation measurement,Shape measurement,Subspace constraints,factorization algorithm,focal length,image measurement,image reconstruction,image sequence,image sequences,intrinsic camera parameter,linear closed-form solution,reconstructed projective depth,rigid rotation,rigid translation,shape model,uncalibrated perspective reconstruction},
pages = {1075--1082 Vol. 2},
title = {{Uncalibrated perspective reconstruction of deformable structures}},
volume = {2},
year = {2005}
}
@inproceedings{Blanz:1999:MMS:311535.311556,
address = {New York, NY, USA},
author = {Blanz, Volker and Vetter, Thomas},
booktitle = {Proc. 26th Annual Conference on Computer Graphics and Interactive Techniques},
doi = {10.1145/311535.311556},
file = {:home/tiwasaki/Documents/Mendeley/Blanz, Vetter/Proc. 26th Annual Conference on Computer Graphics and Interactive Techniques/Blanz, Vetter - 1999 - A Morphable Model for the Synthesis of 3D Faces.pdf:pdf},
isbn = {0-201-48560-5},
keywords = {computer vision,facial animation,facial modeling,morphing,photogrammetry,registration},
pages = {187--194},
publisher = {ACM Press/Addison-Wesley Publishing Co.},
series = {SIGGRAPH '99},
title = {{A Morphable Model for the Synthesis of 3D Faces}},
url = {http://dx.doi.org/10.1145/311535.311556},
year = {1999}
}
@article{2012,
abstract = {本研究では，拡張現実感により現実空間における光源環境を再現し，その中で対数美的曲面をシミュレーションするシステムを開発した．具体的には，精密な拡散反射色で曲面の映り込みを再現するため，金属半球に反射した光源環境を球面調和解析した結果を用いてレンダリングを行った．また，開発したシステムを用いて，様々な光源環境下（晴天，曇天，夕日）における曲面の印象の違いに関する評価実験を行い，光源環境が曲面の印象に与える影響を明確にした．In this study, we developed a simulation system that reproduced the light source environment in a real world with Augmented Reality, and simulated log-aesthetic curved surfaces in the system. Concretely, this system renders the curved surfaces using the result of spherical harmonics analysis of the light source environment image that is reflected on the metallic hemisphere in order to reproduce the diffuse reflection of the curved surface. Moreover, we experimented in the impression evaluation of the curved surfaces under various environments (fine, cloudy, and evening sun, etc.) with the developed systems and clarified the influence of the light source environment to the impression of curved surfaces.},
author = {{平野 亮} and {原田 利宣} and 床井浩平},
file = {:home/tiwasaki/Documents/Mendeley/亮, 利宣, 浩平/情処学論/亮, 利宣, 浩平 - 2012 - 拡張現実感を用いた様々な光源環境下における対数美的曲面の再現に関する研.pdf:pdf},
issn = {1882-7764},
journal = {情報処理学会論文誌},
number = {8},
pages = {2028--2035},
publisher = {情報処理学会},
title = {拡張現実感を用いた様々な光源環境下における対数美的曲面の再現に関する研究},
url = {http://ci.nii.ac.jp/naid/110009464347},
volume = {53},
year = {2012}
}
@article{Gatos2006317,
author = {Gatos, B and Pratikakis, I and Perantonis, S J},
doi = {http://dx.doi.org/10.1016/j.patcog.2005.09.010},
file = {:home/tiwasaki/Documents/Mendeley/Gatos, Pratikakis, Perantonis/Pattern Recognition/Gatos, Pratikakis, Perantonis - 2006 - Adaptive degraded document image binarization.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
keywords = {Degraded document images,Local adaptive binarization},
number = {3},
pages = {317--327},
title = {{Adaptive degraded document image binarization}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320305003821},
volume = {39},
year = {2006}
}
@inproceedings{Urtasun2005,
abstract = { We advocate the use of scaled Gaussian process latent variable models (SGPLVM) to learn prior models of 3D human pose for 3D people tracking. The SGPLVM simultaneously optimizes a low-dimensional embedding of the high-dimensional pose data and a density function that both gives higher probability to points close to training data and provides a nonlinear probabilistic mapping from the low-dimensional latent space to the full-dimensional pose space. The SGPLVM is a natural choice when only small amounts of training data are available. We demonstrate our approach with two distinct motions, golfing and walking. We show that the SGPLVM sufficiently constrains the problem such that tracking can be accomplished with straightforward deterministic optimization.},
author = {Urtasun, Raquel and Fleet, David J. and Hertzmann, Aaron and Fua, Pascal},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2005.193},
file = {:home/tiwasaki/Documents/Mendeley/Urtasun et al/Proceedings of the IEEE International Conference on Computer Vision/Urtasun et al. - 2005 - Priors for people tracking from small training sets.pdf:pdf},
isbn = {076952334X},
issn = {1550-5499},
pages = {403--410},
title = {{Priors for people tracking from small training sets}},
volume = {I},
year = {2005}
}
@article{Bartoli2006,
abstract = {Registering images of a deforming surface is a well-studied problem. So- lutions include computing optic flow or estimating a parameterized motion model. In the case of optic flowit is necessary to include some regularization. We propose an approach based on representing the induced transforma- tion between images using Radial Basis Functions (RBF). The approach can be viewed as a direct, i.e. intensity-based, method, or equivalently, as a way of using RBFs as non-linear regularizers on the optic flow field. The approach is demonstrated on several image sequences of deforming surfaces. It is shown that the computed registrations are sufficiently accurate to allow convincing augmentations of the images.},
author = {Bartoli, Adrien and Zisserman, Andrew and Bartoli, Adrien and Zisserman, Andrew and Estimation, Direct and Registrations, Non-rigid and Bartoli, Adrien and Zisserman, Andrew},
file = {:home/tiwasaki/Documents/Mendeley/Bartoli et al/Unknown/Bartoli et al. - 2006 - Direct Estimation of Non-Rigid Registrations To cite this version Direct Estimation of Non-Rigid Registrations.pdf:pdf},
pages = {899--908},
title = {{Direct Estimation of Non-Rigid Registrations To cite this version : Direct Estimation of Non-Rigid Registrations}},
year = {2006}
}
@article{Bradley2009a,
author = {Bradley, Derek and Roth, Gerhard and Bose, Prosenjit},
doi = {10.1007/s00138-007-0108-9},
file = {:home/tiwasaki/Documents/Mendeley/Bradley, Roth, Bose/Machine Vision and Applications/Bradley, Roth, Bose - 2009 - Augmented reality on cloth with realistic illumination.pdf:pdf},
isbn = {0013800701},
issn = {09328092},
journal = {Machine Vision and Applications},
keywords = {AR,Augmented reality,Common illumination,Marker systems,Non-rigid object tracking},
mendeley-tags = {AR},
number = {2},
pages = {85--92},
title = {{Augmented reality on cloth with realistic illumination}},
volume = {20},
year = {2009}
}
@inproceedings{Uchiyama2011a,
author = {Uchiyama, Hideaki and Saito, Hideo},
booktitle = {IEEE Virtual Reality Conference},
file = {:home/tiwasaki/Documents/Mendeley/Uchiyama, Saito/IEEE Virtual Reality Conference/Uchiyama, Saito - 2011 - Random Dot Markers.pdf:pdf},
isbn = {9781457700385},
pages = {35--38},
title = {{Random Dot Markers}},
year = {2011}
}
@inproceedings{Comport:2003:RTM:946248.946787,
address = {Washington, DC, USA},
author = {Comport, Andrew I and Marchand, {\'{E}}ric and Chaumette, Fran{\c{c}}ois},
booktitle = {Proc. 2nd IEEE/ACM International Symposium on Mixed and Augmented Reality, ISMAR},
file = {:home/tiwasaki/Documents/Mendeley/Comport et al/IEEE Transactions on Visualization and Computer Graphics/Comport et al. - 2006 - Real-time markerless tracking for augmented reality The virtual visual servoing framework.pdf:pdf},
isbn = {0-7695-2006-5},
pages = {36----},
publisher = {IEEE Computer Society},
series = {ISMAR '03},
title = {{A Real-time Tracker for Markerless Augmented Reality}},
url = {http://dl.acm.org/citation.cfm?id=946248.946787},
year = {2003}
}
@article{Zhou2008,
abstract = {Although Augmented Reality technology was first developed over forty years ago, there has been little survey work giving an overview of recent research in the field. This paper reviews the ten-year development of the work presented at the ISMAR conference and its predecessors with a particular focus on tracking, interaction and display research. It provides a roadmap for future augmented reality research which will be of great value to this relatively young field, and also for helping researchers decide which topics should be explored when they are beginning their own studies in the area.},
author = {Zhou, Feng and Dun, Henry Been Lirn and Billinghurst, Mark},
doi = {10.1109/ISMAR.2008.4637362},
file = {:home/tiwasaki/Documents/Mendeley/Zhou, Dun, Billinghurst/Proceedings - 7th IEEE International Symposium on Mixed and Augmented Reality 2008, ISMAR 2008/Zhou, Dun, Billinghurst - 2008 - Trends in augmented reality tracking, interaction and display A review of ten years of ISMAR.pdf:pdf},
isbn = {9781424428403},
journal = {Proceedings - 7th IEEE International Symposium on Mixed and Augmented Reality 2008, ISMAR 2008},
keywords = {AR application,AR display,Augmented reality,Calibration and registration,Camera calibration,Interaction,Tracking},
mendeley-tags = {Camera calibration},
pages = {193--202},
title = {{Trends in augmented reality tracking, interaction and display: A review of ten years of ISMAR}},
year = {2008}
}
@article{Comport2006,
abstract = {Tracking is a very important research subject in a real-time augmented reality context. The main requirements for trackers are high accuracy and little latency at a reasonable cost. In order to address these issues, a real-time, robust, and efficient 3D model-based tracking algorithm is proposed for a "video see through" monocular vision system. The tracking of objects in the scene amounts to calculating the pose between the camera and the objects. Virtual objects can then be projected into the scene using the pose. Here, nonlinear pose estimation is formulated by means of a virtual visual servoing approach. In this context, the derivation of point-to-curves interaction matrices are given for different 3D geometrical primitives including straight lines, circles, cylinders, and spheres. A local moving edges tracker is used in order to provide real-time tracking of points normal to the object contours. Robustness is obtained by integrating an M-estimator into the visual control law via an iteratively reweighted least squares implementation. This approach is then extended to address the 3D model-free augmented reality problem. The method presented in this paper has been validated on several complex image sequences including outdoor environments. Results show the method to be robust to occlusion, changes in illumination, and mistracking.},
author = {Comport, Andrew I. and Marchand, Eric and Pressigout, Muriel and Chaumette, Fran{\c{c}}ois},
doi = {10.1109/TVCG.2006.78},
file = {:home/tiwasaki/Documents/Mendeley/Comport et al/IEEE Transactions on Visualization and Computer Graphics/Comport et al. - 2006 - Real-time markerless tracking for augmented reality The virtual visual servoing framework.pdf:pdf},
isbn = {1077-2626 VO - 12},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Augmented reality,Model-based tracking,Model-free tracking,Real-time,Robust estimators,Virtual visual servoing},
number = {4},
pages = {615--628},
pmid = {16805268},
title = {{Real-time markerless tracking for augmented reality: The virtual visual servoing framework}},
volume = {12},
year = {2006}
}
@article{Yu2009,
abstract = {A fully affine invariant image comparison method, Affine-SIFT (ASIFT) is introduced. While SIFT is fully invariant with respect to only four parameters namely zoom, rotation and translation, the new method treats the two left over parameters : the angles defining the camera axis orientation. Against any prognosis, simulating all views depending on these two parameters is feasible. The method permits to reliably identify features that have undergone very large affine distortions measured by a new parameter, the transition tilt. State-of-the-art methods hardly exceed transition tilts of 2 (SIFT), 2.5 (Harris-Affine and Hessian-Affine) and 10 (MSER). ASIFT can handle transition tilts up 36 and higher (see Fig. 1).},
author = {Yu, Guoshen and Morel, Jm},
doi = {10.1109/ICASSP.2009.4959904},
file = {:home/tiwasaki/Documents/Mendeley/Yu, Morel/IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP/Yu, Morel - 2009 - A fully affine invariant image comparison method.pdf:pdf},
isbn = {9781424423538},
issn = {01628828},
journal = {IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP},
number = {1},
pages = {1597--1600},
title = {{A fully affine invariant image comparison method}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4959904},
volume = {26},
year = {2009}
}
@article{Hirano2012,
author = {亮, 平野 and 利宣, 原田 and 浩平, 床井},
file = {:home/tiwasaki/Documents/Mendeley/亮, 利宣, 浩平/情処学論/亮, 利宣, 浩平 - 2012 - 拡張現実感を用いた様々な光源環境下における対数美的曲面の再現に関する研.pdf:pdf},
journal = {情処学論},
keywords = {augmented reality,impression evaluation,log-aesthetic curved surface,precomputed radiance},
number = {8},
pages = {2028--2035},
title = {拡張現実感を用いた様々な光源環境下における対数美的曲面の再現に関する研究},
volume = {53},
year = {2012}
}
@phdthesis{MarinaAtsumiOikawa2013,
author = {{Marina, Atsumi}, Oikawa},
booktitle = {奈良先端大学院},
file = {:home/tiwasaki/Documents/Mendeley/Marina, Atsumi/奈良先端大学院/Marina, Atsumi - 2013 - Doctoral Dissertation A model-based tracking framework for non-textured 3D rigid curved objects using sparse (2).pdf:pdf},
pages = {143},
title = {{Doctoral Dissertation A model-based tracking framework for non-textured 3D rigid curved objects using sparse polygonal meshes Marina Atsumi Oikawa}},
year = {2013}
}
@article{Pilet2008,
abstract = {We present a real-time method for detecting deformable surfaces, with no need whatsoever for a priori pose knowledge. Our method starts from a set of wide baseline point matches between an undeformed image of the object and the image in which it is to be detected. The matches are used not only to detect but also to compute a precise mapping from one to the other. The algorithm is robust to large deformations, lighting changes, motion blur, and occlusions. It runs at 10 frames per second on a 2.8 GHz PC. We demonstrate its applicability by using it to realistically modify the texture of a deforming surface and to handle complex illumination effects. Combining deformable meshes with a well designed robust estimator is key to dealing with the large number of parameters involved in modeling deformable surfaces and rejecting erroneous matches for error rates of more than 90{\%}, which is considerably more than what is required in practice.},
author = {Pilet, Julien and Lepetit, Vincent and Fua, Pascal},
doi = {10.1007/s11263-006-0017-9},
file = {:home/tiwasaki/Documents/Mendeley/Pilet, Lepetit, Fua/International Journal of Computer Vision/Pilet, Lepetit, Fua - 2008 - Fast non-rigid surface detection, registration and realistic augmentation.pdf:pdf},
isbn = {0920-5691},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {Non-rigid augmented reality,Non-rigid detection,Real-time deformable registration},
number = {2},
pages = {109--122},
pmid = {12892705},
title = {{Fast non-rigid surface detection, registration and realistic augmentation}},
volume = {76},
year = {2008}
}
@inproceedings{Narita:2015:DPM:2821592.2821618,
address = {New York, NY, USA},
author = {Narita, Gaku and Watanabe, Yoshihiro and Ishikawa, Masatoshi},
booktitle = {Proc. 21st ACM Symposium on Virtual Reality Software and Technology, SVRST},
doi = {10.1145/2821592.2821618},
file = {:home/tiwasaki/Documents/Mendeley/Narita, Watanabe, Ishikawa/Proc. 21st ACM Symposium on Virtual Reality Software and Technology, SVRST/Narita, Watanabe, Ishikawa - 2015 - Dynamic Projection Mapping Onto a Deformable Object with Occlusion Based on High-speed Tracking of D.pdf:pdf},
isbn = {978-1-4503-3990-2},
keywords = {augmented reality,deformable object,high-speed vision,projection mapping,tracking},
pages = {149--152},
publisher = {ACM},
series = {VRST '15},
title = {{Dynamic Projection Mapping Onto a Deformable Object with Occlusion Based on High-speed Tracking of Dot Marker Array}},
url = {http://doi.acm.org/10.1145/2821592.2821618},
year = {2015}
}
@article{Emori2004,
abstract = {Digital archiving of cultural heritages has recently been broadening in the way of using them. However such digital contents are only shown in display, and cannot be touched. In this paper, we propose a system that displays textures of the digital contents on real objects via video-see-through HMD, so that we can touch the digital archives in the real world. The textures are deformed by an appropriate geometric transformation, and overlaid onto the deformable surface of the object in real time. For demonstrating the effectiveness of the proposed system, we develop a system that displays digitally scanned images of rare books on paper surface on blank books.},
author = {基倫, 江森 and 英雄, 斎藤},
file = {:home/tiwasaki/Documents/Mendeley/基倫, 英雄/日本バーチャルリアリティ学会論文誌/基倫, 英雄 - 2004 - HMDを用いた形状可変物体表面へのテクスチャ重畳表示システム.pdf:pdf},
issn = {1344011X},
journal = {日本バーチャルリアリティ学会論文誌},
number = {3},
pages = {309--317},
publisher = {日本バーチャルリアリティ学会},
title = {{HMDを用いた形状可変物体表面へのテクスチャ重畳表示システム}},
url = {http://ci.nii.ac.jp/naid/110008746947},
volume = {9},
year = {2004}
}
@article{Zhang1997,
abstract = {We present a novel technique for effectively calibrating a binocular stereo rig using the information from both scenes and classical cal- ibration objects. The calibration provided by the classical methods is only valid for the space near the position of the calibration object. Our technique tries to make the best use of the rigidity of the ge- ometry between two cameras. The idea is to first estimate precisely the epipolar geometry which is valid for a wide range in space from all available matches, extracted from both the environment and the calibration objects. This allows us to conduct an accurate projective reconstruction. Using the a pri- ori knowledge of the calibration object, we are finally able to cali- brate the stereo rig in a Euclidean space. The proposed technique has been tested with a number of real images, and significant im- provement has been observed. A WWW demo with more examples and experimental data is available at http://www.inria.fr/robotvis/ personnel/zzhang/ CalibEnv/CalibEnv.html.},
author = {Zhang, Zhengyou and Faugeras, Olivier and Deriche, Rachid},
journal = {J. Computer Vision Research},
keywords = {camera calibration,on-line calibration,stereo vision},
number = {1},
pages = {58----68},
title = {{An Effective Technique for Calibrating a Binocular Stereo through Projective Reconstruction Using Both a Calibration Object and the Environment}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.34.585{\&}rep=rep1{\&}type=pdf},
volume = {1},
year = {1997}
}
@article{Hirokazu1999a,
abstract = {We describe an augmented reality conferencing system which uses the overlay of virtual images on the real world. Remote collaborators are represented on Virtual Monitors which can be freely positioned about a user in space. Users can collaboratively view and interact with virtual objects using a shared virtual whiteboard. This is possible through precise virtual image registration using fast and accurate computer vision techniques and HMD calibration. We propose a method for tracking fiducial markers and a calibration method for optical see-through HMD based on the marker tracking.},
annote = {RANSACの原著論文},
author = {Hirokazu, Kato and Billinghurst, Mark},
doi = {10.1109/IWAR.1999.803809},
file = {:home/tiwasaki/Documents/Mendeley/Hirokazu, Billinghurst/Proc. 2nd IEEE and ACM International Workshop on Augmented Reality, IWAR/Hirokazu, Billinghurst - 1999 - Marker tracking and HMD calibration for a video-based augmented reality conferencing system.pdf:pdf},
isbn = {0-7695-0359-4},
issn = {16136829},
journal = {Proc. 2nd IEEE and ACM International Workshop on Augmented Reality, IWAR},
keywords = {AR},
mendeley-tags = {AR},
pages = {85--94},
title = {{Marker tracking and HMD calibration for a video-based augmented reality conferencing system}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=803809},
year = {1999}
}
@article{Zhao2009,
abstract = {Typical Human Robot Interaction (HRI) assumes that the user explicitly interacts with robots. However, explicit control with robots can be unnecessary or even undesirable in certain cases, such as dealing with domestic services (or housework). In this paper, the authors propose an alternative strategy of interaction: the user implicitly controls a robot by issuing commands on corresponding real world objects and the environment. Robots then discover these commands and complete them in the background. A paper-tag-based interface was implemented to support such implicit robot control in a sensor-augmented home environment. The authors' initial user studies indicated that the paper-tag-based interface is particularly simple to use and provides users with flexibility in planning and controlling their housework tasks in a simulated home environment.},
author = {Zhao, S and Nakamura, K and Ishii, K and Igarashi, T},
doi = {10.1145/1518701.1518730},
file = {:home/tiwasaki/Documents/Mendeley/Zhao et al/Conference on Human Factors in Computing Systems Proceedings/Zhao et al. - 2009 - Magic Cards A Paper Tag Interface for Implicit Robot Control.pdf:pdf},
isbn = {9781605582467},
journal = {Conference on Human Factors in Computing Systems Proceedings},
pages = {173--182},
title = {{Magic Cards: A Paper Tag Interface for Implicit Robot Control}},
url = {http://ezproxy.net.ucf.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=ega{\&}AN=ega235531{\&}site=ehost-live},
year = {2009}
}
@article{Yao2007,
abstract = {Apomixis represents an alteration of classical sexual plant reproduction to produce seeds with essentially clonal embryos, stimulating wide interest from biologists and plant breeders for its ability to fix heterosis. Eulaliopsis binata (Poaceae), is identified here as a new apomictic species. Embryological investigation indicates that the developmental pattern of embryo sac formation in E. binata represents gametophytic apospory, the embryo originating from an unreduced cell, without fertilization and the mode of endosperm development was autonomous. Sexual embryo sacs were found with a frequency of 1-4{\%} depending on the biotype. The DNA content of nuclei (C-value) in mature seeds was screened by flow cytometry (FCSS) and demonstrated that the endosperm was derived autonomously without fertilization and the three biotypes of E. binata showed varying degrees of apomixis. The Wide-leaf type showed obligate apomixis whereas the Slender-leaf and the Red-haulm type displayed facultative apomixis. In addition, adventitious embryos were observed on the wall of ovary, integument and nucellus cells, indicating that E. binata produces embryos via a mixture of apospory and adventitious embryony.},
author = {Yao, Jia Ling and Zhou, Yun and Hu, Chun G.},
doi = {10.1007/s00497-007-0051-y},
file = {:home/tiwasaki/Documents/Mendeley/Yao, Zhou, Hu/Sexual Plant Reproduction/Yao, Zhou, Hu - 2007 - Apomixis in Eulaliopsis binata Characterization of reproductive mode and endosperm development.pdf:pdf},
isbn = {0934-0882},
issn = {09340882},
journal = {Sexual Plant Reproduction},
keywords = {Adventitious embryony,Apomixis,Apospory,Autonomous endosperm,Eulaliopsis binata},
number = {3},
pages = {151--158},
title = {{Apomixis in Eulaliopsis binata: Characterization of reproductive mode and endosperm development}},
volume = {20},
year = {2007}
}
@article{Lee2011,
abstract = {Typically, vision-based AR systems operate on the basis of prior knowledge of the environment such as a square marker. One problem of traditional marker-based AR system has a limitation that the marker has to be located in the sensing range. Therefore, there have been considerable research efforts for the techniques known as real-time camera tracking, in which the system attempts to add unknown 3D features to its feature map, and these then provide registration even when the reference map is out of the sensing range. In this paper, we describe a real-time camera tracking framework specifically designed to track a monocular camera in a desktop workspace. Basic idea of the proposed scheme is that a real-time camera tracking is achieved on the basis of a plane tracking algorithm. Also we suggest a method for re-detecting features to maintain registration of virtual objects. The proposed method can cope with the problem that the features cannot be tracked, when they go out of the sensing range. It can be applicable to an augmented reality system for mobile computing environment.},
author = {Lee, Ahyun and Lee, Jae-Young and Lee, Seok-Han and Choi, Jong-Soo},
doi = {10.1109/FCV.2011.5739718},
file = {:home/tiwasaki/Documents/Mendeley/Lee et al/17th Korea-Japan Joint Workshop on Frontiers of Computer Vision, FCV/Lee et al. - 2011 - Markerless augmented reality system based on planar object tracking.pdf:pdf},
isbn = {978-1-61284-676-7},
journal = {17th Korea-Japan Joint Workshop on Frontiers of Computer Vision, FCV},
keywords = {augmented reality,corner detection,markerless,object tracking},
pages = {1--4},
title = {{Markerless augmented reality system based on planar object tracking}},
year = {2011}
}
@article{Blanz2003,
abstract = {This paper presents a method for photo-realistic animation that can be applied to any face shown in a single image or a video. The technique does not require example data of the person's mouth movements, and the image to be animated is not restricted in pose or illumination. Video},
author = {Blanz, V. and Basso, C. and Poggio, T. and Vetter, T.},
doi = {10.1111/1467-8659.t01-1-00712},
file = {:home/tiwasaki/Documents/Mendeley/Blanz et al/Computer Graphics Forum/Blanz et al. - 2003 - Reanimating Faces in Images and Video.pdf:pdf},
issn = {01677055},
journal = {Computer Graphics Forum},
number = {3},
pages = {641--650},
title = {{Reanimating Faces in Images and Video}},
volume = {22},
year = {2003}
}
@article{Nakai2006,
abstract = {Camera-based document image retrieval is a task of searching document images from the database based on query images captured using digital cameras. For this task, it is required to solve the problem of perspective distortion of images, as well as to establish a way of matching document images efficiently. To solve these problems we have proposed a method called Locally Likely Arrangement Hashing (LLAH) which is characterized by both the use of a perspective invariant to cope with the distortion and the efficiency: LLAH only requires O(N) time where N is the number of feature points that describe the query image. In this paper, we introduce into LLAH an affine invariant instead of the perspective invariant so as to improve its adjustability. Experimental results show that the use of the affine invariant enables us to improve either the accuracy from 96.2{\%} to 97.8{\%}, or the retrieval time from 112 msec./query to 75 msec./query by selecting parameters of processing.},
author = {Nakai, Tomohiro and Kise, Koichi and Iwamura, Masakazu},
doi = {10.1007/11669487_48},
file = {:home/tiwasaki/Documents/Mendeley/Nakai, Kise, Iwamura/Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)/Nakai, Kise, Iwamura - 2006 - Use of affine invariants in locally likely arrangement hashing for camera-based document image retrieval.pdf:pdf},
isbn = {3540321403},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {541--552},
title = {{Use of affine invariants in locally likely arrangement hashing for camera-based document image retrieval}},
volume = {3872 LNCS},
year = {2006}
}
@article{Breiman2001,
abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148--156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
author = {Breiman, Leo},
doi = {10.1023/A:1010933404324},
file = {:home/tiwasaki/Documents/Mendeley/Breiman/Machine Learning/Breiman - 2001 - Random Forests.pdf:pdf},
issn = {1573-0565},
journal = {Machine Learning},
number = {1},
pages = {5--32},
title = {{Random Forests}},
url = {http://dx.doi.org/10.1023/A:1010933404324},
volume = {45},
year = {2001}
}
@inproceedings{Salzmann2007a,
abstract = {We study from a theoretical standpoint the ambiguities that occur when tracking a generic deformable surface under monocular perspective projection given 3D to 2D correspondences. We show that, additionally to the known scale ambiguity, a set of potential ambiguities can be clearly identified. From this, we deduce a minimal set of constraints required to disambiguate the problem and incorporate them into a working algorithm that runs on real noisy data.},
author = {Salzmann, Mathieu and Lepetit, Vincent and Fua, Pascal},
booktitle = {Proc. IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CSCCVPR},
doi = {10.1109/CVPR.2007.383238},
file = {:home/tiwasaki/Documents/Mendeley/Salzmann, Lepetit, Fua/Proc. IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CSCCVPR/Salzmann, Lepetit, Fua - 2007 - Deformable surface tracking ambiguities.pdf:pdf},
isbn = {1424411807},
issn = {10636919},
month = {jun},
pages = {1--8},
publisher = {IEEE},
title = {{Deformable surface tracking ambiguities}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4270263},
year = {2007}
}
@article{Ngo2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1503.04643v1},
author = {Ngo, Dat and Ostlund, Jonas and Fua, Pascal},
doi = {10.1109/TPAMI.2015.2435739},
eprint = {arXiv:1503.04643v1},
file = {:home/tiwasaki/Documents/Mendeley/Ngo, Ostlund, Fua/The IEEE Transactions on Pattern Analysis and Machine Intelligence/Ngo, Ostlund, Fua - 2015 - Template-based Monocular 3D Shape Recovery using Laplacian Meshes.pdf:pdf},
isbn = {0162-8828 VO - PP},
issn = {0162-8828},
journal = {The IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Deformable surfaces,Laplacian formalism,Monocular shape recovery},
number = {1},
pages = {172 -- 187},
title = {{Template-based Monocular 3D Shape Recovery using Laplacian Meshes}},
volume = {38},
year = {2015}
}
@article{Lowe1999,
abstract = {An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds},
archivePrefix = {arXiv},
arxivId = {cs/0112017},
author = {Lowe, David G.},
doi = {10.1109/ICCV.1999.790410},
eprint = {0112017},
file = {:home/tiwasaki/Documents/Mendeley/Lowe/Proceedings of the Seventh IEEE International Conference on Computer Vision/Lowe - 1999 - Object recognition from local scale-invariant features.pdf:pdf},
isbn = {0-7695-0164-8},
issn = {0-7695-0164-8},
journal = {Proceedings of the Seventh IEEE International Conference on Computer Vision},
keywords = {Objectrecognition,SIFT},
mendeley-tags = {Objectrecognition,SIFT},
number = {[8},
pages = {1150--1157},
pmid = {15806121},
primaryClass = {cs},
title = {{Object recognition from local scale-invariant features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=790410},
volume = {2},
year = {1999}
}
@article{Shimizu2012,
abstract = {本稿では，2 段階の Randomized Trees による高精度かつ高速なキーポイントマッチング手法を提案する． 従来法である Randomized Trees を用いたキーポイントの分類手法では，高精度なリアルタイムのキーポイントマッチ ングを実現している．しかし，Randomized Trees で表現するテンプレートの視点は多様であり，1 つの Randomized Trees では，全ての変化において高精度なキーポイントの分類は困難である．そこで，提案手法では 1 段階目にテン プレートの視点を分類し，2 段階目に，1 段階目で分類した視点ごとの Randomized Trees によりキーポイントの分類 を行う．評価実験より，提案手法は対象物体の視点が 70 度回転した画像において，SIFT より 88.4{\%}，Randomized Trees より 63.4{\%}の精度を向上させることができた．また，提案手法は約 12 fps でリアルタイムにキーポイントマッ チングが可能であることを確認した．},
author = {孝, 西村 and 彰一, 清水 and 弘亘, 藤吉},
doi = {10.1587/transinf.E95.D.1766},
file = {:home/tiwasaki/Documents/Mendeley/孝, 彰一, 弘亘/画像の認識・理解シンポジウム (MIRU2010)/孝, 彰一, 弘亘 - 2010 - 2段階のRandomized Treesを用いたキーポイントの分類.pdf:pdf},
isbn = {9784901122115},
issn = {09168532},
journal = {画像の認識・理解シンポジウム (MIRU2010)},
keywords = {Keypoint matching,Randomized trees,Viewpoint estimation},
pages = {1--8},
pmid = {16929732},
title = {{2段階のRandomized Treesを用いたキーポイントの分類}},
year = {2010}
}
@inproceedings{Klein:2007:PTM:1514339.1514363,
address = {Washington, DC, USA},
author = {Klein, Georg and Murray, David},
booktitle = {Proc. 6th IEEE and ACM International Symposium on Mixed and Augmented Reality, ISMAR},
doi = {10.1109/ISMAR.2007.4538852},
file = {:home/tiwasaki/Documents/Mendeley/Klein, Murray/Proc. 6th IEEE and ACM International Symposium on Mixed and Augmented Reality, ISMAR/Klein, Murray - 2007 - Parallel Tracking and Mapping for Small AR Workspaces.pdf:pdf},
isbn = {978-1-4244-1749-0},
pages = {1--10},
publisher = {IEEE Computer Society},
series = {ISMAR '07},
title = {{Parallel Tracking and Mapping for Small AR Workspaces}},
url = {http://dx.doi.org/10.1109/ISMAR.2007.4538852},
year = {2007}
}
@article{2006,
abstract = {本論文では,ディジタルカメラで撮影して得られた文書画像をもとに,データベースから対応する文書画像を見つける文書画像検索の手法を提案する.従来のスキャナを利用した文書画像検索と異なり,ディジタルカメラを利用する場合には射影ひずみなどのディジタルカメラ特有の問題に対処する必要がある.また,大規模データベースでの利用を可能にするため,検索の効率性も重要である.これらの問題に対処するため,本論文では特徴点の局所的配置を特徴量とし,ハッシュ表を用いた投票によって検索する手法を提案する.本手法では,射影ひずみを実用的な範囲に制限し,特徴点の組合せを局所領域に限定することで,計算量の削減を実現する.また,高精度な検索を実現するため,射影変換の不変量である複比で特徴点の配置を表現し,特徴量としている.実験により,10,000ページのデータベースから精度98{\%},平均処理時間約160ms(特徴点抽出の画像処理に要する約1sを除く)で検索できることが示された.},
author = {中居, 友弘 and 黄瀬, 浩一 and 岩村, 雅一},
file = {:home/tiwasaki/Documents/Mendeley/中居, 黄瀬, 岩村/電子情報通信学会論文誌. D, 情報・システム/中居, 黄瀬, 岩村 - 2006 - 特徴点の局所的配置に.pdf:pdf},
issn = {18804535},
journal = {電子情報通信学会論文誌. D, 情報・システム},
number = {9},
pages = {2045--2054},
publisher = {一般社団法人電子情報通信学会},
title = {特徴点の局所的配置に基づくディジタルカメラを用いた高速文書画像検索(画像認識,コンピュータビジョン)},
url = {http://ci.nii.ac.jp/naid/110007380548},
volume = {89},
year = {2006}
}
@article{Lepetit:2006:KRU:1159166.1159350,
address = {Washington, DC, USA},
author = {Lepetit, Vincent and Fua, Pascal},
doi = {10.1109/TPAMI.2006.188},
file = {:home/tiwasaki/Documents/Mendeley/Lepetit, Fua/IEEE Trans. Pattern Anal. Mach. Intell/Lepetit, Fua - 2006 - Keypoint Recognition Using Randomized Trees.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
keywords = {Image processing and computer vision,classifier design and evaluation,edge and feature detection.,object recognition,statistical,tracking},
number = {9},
pages = {1465--1479},
publisher = {IEEE Computer Society},
title = {{Keypoint Recognition Using Randomized Trees}},
url = {http://dx.doi.org/10.1109/TPAMI.2006.188},
volume = {28},
year = {2006}
}
@article{Salzmann2007,
author = {Salzmann, Mathieu and Pilet, Julien and Ilic, Slobodan and Fua, Pascal},
doi = {10.1109/TPAMI.2007.1080},
file = {:home/tiwasaki/Documents/Mendeley/Salzmann et al/IEEE Transactions on Pattern Analysis and Machine Intelligence/Salzmann et al. - 2007 - Surface Deformation Models for Nonrigid 3D Shape Recovery.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = {aug},
number = {8},
pages = {1481--1487},
title = {{Surface Deformation Models for Nonrigid 3D Shape Recovery}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4250473},
volume = {29},
year = {2007}
}
@article{Liang2015,
author = {Liang, H and Liang, R and Song, M and He, X},
doi = {10.1109/TCYB.2015.2417211},
file = {:home/tiwasaki/Documents/Mendeley/Liang et al/IEEE Transactions on Cybernetics/Liang et al. - 2015 - Coupled dictionary learning for the detail-enhanced synthesis of 3-D facial expressions.pdf:pdf},
issn = {2168-2267},
journal = {IEEE Transactions on Cybernetics},
number = {99},
pages = {1},
title = {{Coupled dictionary learning for the detail-enhanced synthesis of 3-D facial expressions}},
volume = {PP},
year = {2015}
}
@article{Salzmann2007b,
author = {Salzmann, Mathieu and Hartley, Richard and Fua, Pascal},
doi = {10.1109/ICCV.2007.4409031},
file = {:home/tiwasaki/Documents/Mendeley/Salzmann, Hartley, Fua/Constraints/Salzmann, Hartley, Fua - 2007 - Convex Optimization for Deformable Surface 3 – D Tracking.pdf:pdf},
isbn = {9781424416318},
issn = {1550-5499},
journal = {Constraints},
pages = {0--7},
title = {{Convex Optimization for Deformable Surface 3 – D Tracking}},
year = {2007}
}
@article{Lima2010,
abstract = {This paper presents the implementation of 3D tracking techniques based on natural features for augmented reality. The contemplated techniques are from the model based category, comprising recursive and non-recursive methods, as well as edge and texture based techniques. An evaluation of the implemented 3D trackers was performed regarding performance and accuracy under different scenarios.},
author = {Lima, Jp and Sim{\~{o}}es, Francisco and Figueiredo, Lucas and Kelner, Judith},
file = {:home/tiwasaki/Documents/Mendeley/Lima et al/Sbc/Lima et al. - 2010 - Model Based Markerless 3D Tracking Applied to Augmented Reality.pdf:pdf},
journal = {Sbc},
keywords = {augmented reality,computer vision,markerless tracking},
pages = {2--15},
title = {{Model Based Markerless 3D Tracking Applied to Augmented Reality}},
url = {http://cin.ufpe.br/{~}in1123/material/10038.pdf},
volume = {1},
year = {2010}
}

@misc{Image2,
    url="https://www.pakutaso.com/20160638162post-8115.html"
}
